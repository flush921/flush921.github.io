# 逻辑斯蒂回归模型
## 逻辑斯蒂分布

![Image](https://github.com/user-attachments/assets/f0e5d568-3ba8-49d7-a9ff-72e10e4cfb1d)

## 二项逻辑斯蒂回归模型（实际是一种分类模型）
![Image](https://github.com/user-attachments/assets/5056c7b7-c488-4401-aca6-248f3251eedd)

回顾：**统计学习方法** = **模型**（决策树...）+ **策略**（评分标准）+ **算法**（如何找到最优评分模型的方法）

逻辑斯蒂模型：
![Image](https://github.com/user-attachments/assets/d67ecc60-8604-4cf9-b222-ed486cd94fb7)

![Image](https://github.com/user-attachments/assets/daa31467-ad27-4f39-bd19-80491d90ce36)

![Image](https://github.com/user-attachments/assets/1db22f05-9a2f-4d69-b5b3-112ba1dabe33)

![Image](https://github.com/user-attachments/assets/8d637a74-4441-4566-84e6-98972230ccf9)

这也说明了为什么有时候要归一化，以 $x^{(1)} + x^{(2)} + 3 = z$ 为例子, 对于 $x^{(2)} = 20000$ 、 $x^{(1)} = 1$ 的时候, 为了使sigmoid(z)不一直处在趋于1的区域, 必须归一化

## 模型参数估计（算法）
![Image](https://github.com/user-attachments/assets/d111a156-78ec-43f6-a675-98051b40b0e8)
举例：
![Image](https://github.com/user-attachments/assets/6921e314-2c71-4f9e-ba2e-d9b11c5c349f)

![Image](https://github.com/user-attachments/assets/684a4c2b-a218-44ed-8386-63158cb9db08)

![Image](https://github.com/user-attachments/assets/0058f6c7-5729-4f60-a9b3-e4df58cb8574)
以上这张图就涉及到了数值分析的内容（理解梯度下降：https://blog.csdn.net/qq_41800366/article/details/86583789）

## 多项逻辑斯蒂回归模型
![Image](https://github.com/user-attachments/assets/b6d5bb82-e30b-43a6-b84c-1b1ec9730484)

